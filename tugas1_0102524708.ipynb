{"cells":[{"cell_type":"markdown","id":"a9c8c3b3","metadata":{"id":"a9c8c3b3"},"source":["# Natural Language Processing\n","\n","## Tugas 1: Regular Expressions & Model Bahasa N-gram\n","\n","### Mekanisme\n","\n","Anda hanya diwajibkan untuk mengumpulkan file ini saja ke uploader yang disediakan di https://elearning.uai.ac.id/. Ganti nama file ini saat pengumpulan menjadi **tugas1_NIM.ipynb**.\n","\n","**Keterlambatan**: Pengumpulan tugas yang melebihi tenggat yang telah ditentukan tidak akan diterima. Keterlambatan akan berakibat pada nilai nol untuk tugas ini.\n","\n","**Kolaborasi**: Anda diperbolehkan untuk berdiskusi dengan teman Anda, tetapi dilarang keras menyalin kode maupun tulisan dari teman Anda.\n","\n","### Petunjuk\n","\n","Pastikan jawaban Anda singkat, padat, dan jelas. Mayoritas pertanyaan yang diberikan dapat dijawab dalam 3-4 kalimat saja."]},{"cell_type":"code","execution_count":13,"id":"fc2bd648","metadata":{"id":"fc2bd648","executionInfo":{"status":"ok","timestamp":1745636673479,"user_tz":-420,"elapsed":4,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","id":"9abe8d33","metadata":{"id":"9abe8d33"},"source":["## 1. Regular Expressions (5 poin)"]},{"cell_type":"markdown","id":"08817304","metadata":{"id":"08817304"},"source":["### Soal 1.1 (2 poin)\n","\n","Cari pola regular expression yang dapat mencocokkan semua elemen di dalam `words_a`, tetapi tidak cocok dengan apa pun di dalam `words_b`."]},{"cell_type":"code","execution_count":9,"id":"6320c1af","metadata":{"id":"6320c1af","executionInfo":{"status":"ok","timestamp":1745636223231,"user_tz":-420,"elapsed":6,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["import pandas as pd\n","\n","words_a = [\n","    \"membacakan\",\n","    \"menuliskan\",\n","    \"melihatkan\",\n","    \"mendengarkan\",\n","    \"mengajarkan\",\n","    \"menarikan\",\n","    \"menyanyikan\",\n","    \"memasakkan\",\n","    \"mencucikan\",\n","    \"membelikan\",\n","    \"menjualkan\",\n","    \"memberikan\",\n","]\n","\n","words_b = [\n","    \"rumah\",\n","    \"meja\",\n","    \"kursi\",\n","    \"ikan\",\n","    \"semen\",\n","    \"ramen\",\n","    \"akan\",\n","    \"bukan\",\n","    \"mental\",\n","]\n","\n","pattern = r\"^me(?:ny|ng|n|m|l|r|b)[a-z]+kan$\"\n","\n","assert pd.Series(words_a).str.contains(pattern).all()\n","assert not pd.Series(words_b).str.match(pattern).any()"]},{"cell_type":"markdown","id":"945567fa","metadata":{"id":"945567fa"},"source":["### Soal 1.2 (3 poin)\n","\n","Cari pola regular expression yang dapat mencocokkan semua elemen di dalam `buah_a`, tetapi tidak cocok dengan apa pun di dalam `buah_b`. Anda hanya boleh menggunakan maksimal 6 karakter untuk pola yang dihasilkan."]},{"cell_type":"code","execution_count":27,"id":"85d3f707","metadata":{"id":"85d3f707","executionInfo":{"status":"ok","timestamp":1745637923620,"user_tz":-420,"elapsed":6,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["import pandas as pd\n","\n","buah_a = [\n","    \"pisang\",\n","    \"mangga\",\n","    \"rambutan\",\n","    \"durian\",\n","    ]\n","\n","buah_b = [\n","    \"pir\",\n","    \"stroberi\",\n","    \"ceri\",\n","    \"kiwi\",\n","    \"leci\",\n","    \"persik\",\n","]\n","\n","pattern = r\"an\"\n","assert len(pattern) <= 6\n","assert pd.Series(buah_a).str.contains(pattern).all()\n","assert not pd.Series(buah_b).str.contains(pattern).any()"]},{"cell_type":"markdown","id":"dc2482f3","metadata":{"id":"dc2482f3"},"source":["## 2. Model Bahasa N-gram (15 poin)"]},{"cell_type":"markdown","id":"01172ef2","metadata":{"id":"01172ef2"},"source":["### Deskripsi Dataset\n","\n","Dataset yang Anda akan gunakan dalam tugas ini adalah [Indonesian News Corpora 300K](https://wortschatz.uni-leipzig.de/en/download/Indonesian#ind_news_2024) tahun 2024 dari Leipzig Corpora Collection."]},{"cell_type":"code","execution_count":null,"id":"0f1d1459","metadata":{"id":"0f1d1459"},"outputs":[],"source":["sentences = pd.read_csv(\n","    \"https://raw.githubusercontent.com/aliakbars/uai-nlp/refs/heads/main/datasets/ind_news_2024_300K-sentences.txt\",\n","    sep=\"\\\\t\",\n","    names=[\"index\", \"text\"],\n",")\n","del sentences[\"index\"]"]},{"cell_type":"markdown","id":"479e18a4","metadata":{"id":"479e18a4"},"source":["### Soal 2.1 (2 poin)\n","\n","Bagilah dataset menjadi data latih dan data uji dengan rasio 80:20."]},{"cell_type":"code","execution_count":6,"id":"e3e423be","metadata":{"id":"e3e423be","executionInfo":{"status":"ok","timestamp":1745639149386,"user_tz":-420,"elapsed":2099,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["sentences = pd.read_csv(\n","    \"https://raw.githubusercontent.com/aliakbars/uai-nlp/refs/heads/main/datasets/ind_news_2024_300K-sentences.txt\",\n","    sep=\"\\\\t\",\n","    names=[\"index\", \"text\"],\n","    engine=\"python\"\n",")\n","del sentences[\"index\"]\n","\n","from sklearn.model_selection import train_test_split\n","\n","train, test = train_test_split(sentences, test_size=0.2, random_state=42)\n","\n","assert len(train) == 240_000\n","assert len(test) == 60_000"]},{"cell_type":"markdown","id":"13e3f971","metadata":{"id":"13e3f971"},"source":["### Soal 2.2 (2 poin)\n","\n","Buatlah tabel `unigram_df` yang menghasilkan **unigram** dari data latih yang telah dihasilkan di atas. Gunakan [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) untuk proses tokenisasi dan menghasilkan unigramnya, serta pola token default `'(?u)\\\\b\\\\w\\\\w+\\\\b'`.\n","\n","Contoh hasil tabel:\n","| word      |   freq |\n","|:----------|-------:|\n","| diketahui |   2654 |\n","| layanan   |   2015 |\n","| maju      |   1386 |\n","| aksi      |   1707 |\n","| januari   |   1316 |"]},{"cell_type":"code","execution_count":8,"id":"e38d629c","metadata":{"id":"e38d629c","executionInfo":{"status":"ok","timestamp":1745639192196,"user_tz":-420,"elapsed":7073,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","import pandas as pd\n","sentences = pd.read_csv(\n","    \"https://raw.githubusercontent.com/aliakbars/uai-nlp/refs/heads/main/datasets/ind_news_2024_300K-sentences.txt\",\n","    sep=\"\\\\t\",\n","    names=[\"index\", \"text\"],\n","    engine=\"python\"\n",")\n","del sentences[\"index\"]\n","\n","vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w\\w+\\b')\n","X_train = vectorizer.fit_transform(train[\"text\"])\n","\n","unigram_df = pd.DataFrame({\n","    \"word\": vectorizer.get_feature_names_out(),\n","    \"freq\": X_train.sum(axis=0).A1\n","}).sort_values(by=\"freq\", ascending=False)\n","\n","assert [\"word\", \"freq\"] == unigram_df.columns.to_list()"]},{"cell_type":"markdown","id":"961fdae1","metadata":{"id":"961fdae1"},"source":["### Soal 2.3 (3 poin)\n","\n","Buatlah tabel `bigram_df` yang menghasilkan **bigram** dari data latih yang telah dihasilkan di atas. Gunakan [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) untuk proses tokenisasi dan menghasilkan bigram, serta pola token default `'(?u)\\\\b\\\\w\\\\w+\\\\b'`. Tambahkan `ooo` sebagai _start token_ dan `zzz` sebagai _end token_.\n","\n","Contoh hasil tabel:\n","| word          | next_word   |   freq |\n","|:--------------|:------------|-------:|\n","| akan          | ada         |    461 |\n","| sebagai       | bentuk      |    365 |\n","| dua           | orang       |    363 |\n","| internasional | zzz         |    385 |\n","| kasus         | ini         |    535 |\n","| kami          | berharap    |    379 |\n","| informasi     | yang        |    398 |\n","| yang          | kita        |    465 |\n","| pada          | musim       |    325 |\n","| tahun         | zzz         |   1060 |"]},{"cell_type":"code","execution_count":9,"id":"4c74d523","metadata":{"id":"4c74d523","executionInfo":{"status":"ok","timestamp":1745639336779,"user_tz":-420,"elapsed":24682,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","import pandas as pd\n","\n","train_modified = train[\"text\"].apply(lambda x: f\"ooo {x.strip()} zzz\")\n","\n","vectorizer = CountVectorizer(ngram_range=(2, 2), token_pattern=r'(?u)\\b\\w\\w+\\b')\n","X_bigram = vectorizer.fit_transform(train_modified)\n","\n","bigram_terms = vectorizer.get_feature_names_out()\n","bigram_freq = X_bigram.sum(axis=0).A1\n","\n","bigram_split = [term.split() for term in bigram_terms]\n","\n","bigram_df = pd.DataFrame(bigram_split, columns=[\"word\", \"next_word\"])\n","bigram_df[\"freq\"] = bigram_freq\n","bigram_df = bigram_df.sort_values(by=\"freq\", ascending=False).reset_index(drop=True)\n","\n","assert [\"word\", \"next_word\", \"freq\"] == bigram_df.columns.to_list()\n","assert \"ooo\" in bigram_df[\"word\"].to_list()\n","assert \"zzz\" in bigram_df[\"next_word\"].to_list()"]},{"cell_type":"markdown","id":"46e915dc","metadata":{"id":"46e915dc"},"source":["### Soal 2.4 (5 poin)\n","\n","Implementasikan kode yang menghasilkan array berisi skor (*log probability*) jika diberikan sebuah kalimat. Petunjuk implementasi:\n","1. Gunakan tabel unigram dan bigram yang telah dihasilkan di soal sebelumnya.\n","1. Gunakan metode Stupid backoff yang menggunakan parameter `alpha` untuk mengatasi kasus bigram yang tidak ditemukan.\n","1. Gunakan metode Laplace smoothing untuk menangani kasus unigram yang tidak ditemukan."]},{"cell_type":"code","execution_count":13,"id":"5a5fa917","metadata":{"id":"5a5fa917","executionInfo":{"status":"ok","timestamp":1745641164915,"user_tz":-420,"elapsed":1667,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["import numpy as np\n","class BigramModel:\n","    def __init__(\n","        self, unigram_df: pd.DataFrame, bigram_df: pd.DataFrame, alpha: float = 0.4\n","    ):\n","        self.unigram_df = unigram_df.set_index(\"word\")\n","        self.bigram_df = bigram_df.set_index([\"word\", \"next_word\"])\n","        self.alpha = alpha\n","        self.total_unigrams = self.unigram_df[\"freq\"].sum()\n","        self.vocab_size = len(self.unigram_df)\n","\n","    def score_unigram(self, word: str) -> float:\n","        count = self.unigram_df[\"freq\"].get(word, 0)\n","        prob = (count + 1) / (self.total_unigrams + self.vocab_size)  # Laplace smoothing\n","        return np.log(prob)\n","\n","    def score(self, word: str, prev_word: str) -> float:\n","        bigram = (prev_word, word)\n","        if bigram in self.bigram_df.index:\n","            bigram_count = self.bigram_df.loc[bigram, \"freq\"]\n","            prev_count = self.unigram_df[\"freq\"].get(prev_word, 0)\n","            if prev_count == 0:\n","                return self.score_unigram(word)\n","            prob = bigram_count / prev_count\n","            return np.log(prob)\n","        else:\n","            return np.log(self.alpha) + self.score_unigram(word)\n","\n","    def sentence_score(self, sentence: str, n: int = 2) -> np.ndarray:\n","        tokens = [\"ooo\"] + sentence.strip().split() + [\"zzz\"]\n","        scores = []\n","        for i in range(1, len(tokens)):\n","            if n == 2:\n","                scores.append(self.score(tokens[i], tokens[i - 1]))\n","            elif n == 1:\n","                scores.append(self.score_unigram(tokens[i]))\n","            else:\n","                raise NotImplementedError(\"Saat ini hanya bisa untuk n=1 atau n=2\")\n","        return np.array(scores)\n","\n","\n","bm = BigramModel(unigram_df, bigram_df, alpha=0.4)\n","assert bm.score_unigram(\"qqq\") > bm.score(\"qqq\", \"xxx\")\n","assert bm.score(\"qqq\", \"xxx\") == np.log(\n","    0.4 * 1 / (unigram_df.freq.sum() + len(unigram_df))\n",")\n","assert bm.score(\"mana\", \"di\") <= 0\n","assert bm.score(\"mungkin\", \"tidak\") > bm.score(\"qqq\", \"xxx\")\n","assert bm.score(\"satu\", \"salah\") > bm.score(\"tangkap\", \"salah\")\n","assert (bm.sentence_score(\"salah satu\") <= 0).all()"]},{"cell_type":"markdown","id":"a9f2b476","metadata":{"id":"a9f2b476"},"source":["### Soal 2.5.a (2 poin)\n","\n","Implementasikan fungsi untuk menghitung perplexity dalam logaritma. Fungsi ini hanya menerima masukan berupa array berisi $\\log P(w_i)$.\n","\n","$$\n","PP(W) = \\sqrt[N]{\\frac{1}{\\prod_{i=1}^N P(w_i)}}\n","$$"]},{"cell_type":"code","execution_count":15,"id":"2499946e","metadata":{"id":"2499946e","executionInfo":{"status":"ok","timestamp":1745641344319,"user_tz":-420,"elapsed":4,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["import numpy as np\n","def perplexity(log_probs: np.ndarray):\n","    N = len(log_probs)\n","    if N == 0:\n","        return 1\n","    perplexity_value = np.exp(-np.sum(log_probs) / N)\n","    return perplexity_value\n","\n","assert perplexity(np.array([0, 0, 0])) == 1\n","assert perplexity(np.array([-10, -20])) == np.exp(15)"]},{"cell_type":"markdown","id":"ba6a33d9","metadata":{"id":"ba6a33d9"},"source":["### Soal 2.5.b (1 poin)\n","\n","Berdasarkan kalimat contoh yang diberikan, periksa dan pastikan bahwa perplexity dari `BigramModel` lebih kecil daripada model unigram."]},{"cell_type":"code","execution_count":23,"id":"f081b329","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f081b329","executionInfo":{"status":"ok","timestamp":1745641986061,"user_tz":-420,"elapsed":10,"user":{"displayName":"","userId":""}},"outputId":"12cbaebf-0577-45a9-a113-a0cf23b2c764"},"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity Bigram: 197.64950856658172\n","Perplexity Unigram: 4352.693526043406\n"]}],"source":["import numpy as np\n","\n","def calculate_perplexity(model, sentence, n=2):\n","    tokens = [\"ooo\"] + sentence.strip().split() + [\"zzz\"]\n","    log_probs = []\n","    for i in range(1, len(tokens)):\n","        if n == 2:\n","            log_prob = model.score(tokens[i], tokens[i-1])\n","        elif n == 1:\n","            log_prob = model.score_unigram(tokens[i])\n","        else:\n","            raise ValueError(\"Only n=1 (unigram) and n=2 (bigram) are supported\")\n","\n","        log_probs.append(log_prob)\n","\n","\n","    return np.exp(-np.sum(log_probs) / len(log_probs))\n","\n","example = \"pengakuan tersebut diungkapkan dalam wawancara dengan media\"\n","\n","perplexity_bigram = calculate_perplexity(bm, example, n=2)\n","perplexity_unigram = calculate_perplexity(bm, example, n=1)\n","\n","print(f\"Perplexity Bigram: {perplexity_bigram}\")\n","print(f\"Perplexity Unigram: {perplexity_unigram}\")\n","\n","assert perplexity_bigram < perplexity_unigram, \"Perplexity Bigram harus lebih kecil daripada Unigram\""]},{"cell_type":"markdown","id":"86f122c9","metadata":{"id":"86f122c9"},"source":["### Soal 2.6 (3 poin)\n","\n","Ambil 30 sampel dari data uji. Hitunglah nilai rata-rata berbobot (_weighted average_) perplexity per kalimat pada data uji dengan menggunakan jumlah kata per kalimat sebagai bobotnya.\n","\n","Pastikan bahwa:\n","1. Metode tokenisasi dan preprocessing yang dilakukan sama dengan soal 2.2 dan 2.3.\n","1. Nilai perplexity dihitung untuk model unigram dan bigram dengan backoff.\n","\n","_Petunjuk: Gunakan metode `.findall()`_"]},{"cell_type":"code","execution_count":31,"id":"8e803681","metadata":{"id":"8e803681","executionInfo":{"status":"ok","timestamp":1745643058182,"user_tz":-420,"elapsed":11,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","from collections import defaultdict\n","\n","def preprocess(text):\n","    return re.findall(r'\\b\\w\\w+\\b', text.lower())\n","\n","class BigramModel:\n","    def __init__(self, unigram_df: pd.DataFrame, bigram_df: pd.DataFrame, alpha: float = 0.4):\n","        self.unigram_df = unigram_df\n","        self.bigram_df = bigram_df\n","        self.alpha = alpha\n","\n","    def score_unigram(self, word: str) -> float:\n","        \"\"\"Menghitung skor unigram dengan Laplace smoothing\"\"\"\n","        if word in self.unigram_df['word'].values:\n","            return np.log(self.unigram_df[self.unigram_df['word'] == word]['probability'].values[0])\n","        else:\n","            return np.log(1 / (self.unigram_df['freq'].sum() + len(self.unigram_df)))\n","\n","    def score(self, word: str, prev_word: str) -> float:\n","        \"\"\"Menghitung skor bigram dengan Stupid Backoff\"\"\"\n","        bigram_prob = self.get_bigram_prob(word, prev_word)\n","        if bigram_prob > 0:\n","            return np.log(bigram_prob)\n","        else:\n","            return np.log(self.alpha) + self.score_unigram(word)\n","\n","    def get_bigram_prob(self, word: str, prev_word: str) -> float:\n","        \"\"\"Mengambil probabilitas bigram\"\"\"\n","        bigram_count = self.bigram_df[(self.bigram_df['word'] == prev_word) & (self.bigram_df['next_word'] == word)]['freq']\n","        if len(bigram_count) > 0:\n","            bigram_freq = bigram_count.values[0]\n","            prev_word_freq = self.unigram_df[self.unigram_df['word'] == prev_word]['freq'].values[0]\n","            return bigram_freq / prev_word_freq\n","        else:\n","            return 0\n","\n","    def sentence_score(self, sentence: str, n: int = 2) -> np.ndarray:\n","        tokens = [\"ooo\"] + preprocess(sentence) + [\"zzz\"]\n","        log_probs = []\n","        for i in range(1, len(tokens)):\n","            if n == 2:\n","                log_prob = self.score(tokens[i], tokens[i-1])\n","            elif n == 1:\n","                log_prob = self.score_unigram(tokens[i])\n","            else:\n","                raise ValueError(\"Only n=1 (unigram) and n=2 (bigram) are supported\")\n"]},{"cell_type":"markdown","id":"ddaa046e","metadata":{"id":"ddaa046e"},"source":["### Soal 2.7 (2 poin)\n","\n","Berikan kesimpulan dari analisis yang sudah dilakukan pada bagian kedua dari tugas ini."]},{"cell_type":"markdown","id":"5576ff95","metadata":{"id":"5576ff95"},"source":["Pada tugas ini, penggunaan Regular Expressions sangat penting dalam tahap tokenisasi dan preprocessing teks. RegEx memungkinkan kita untuk mengidentifikasi dan memanipulasi pola dalam teks, seperti menghapus tanda baca atau memisahkan kata berdasarkan spasi. Ini membantu membersihkan dan mempersiapkan data sebelum digunakan dalam model bahasa n-gram. Meskipun RegEx sangat efektif dalam tugas-tugas pemrosesan teks, tantangan utamanya terletak pada keterbacaan dan kompleksitas sintaksisnya, yang dapat membingungkan bagi pengguna yang kurang berpengalaman.\n","\n","Di sisi lain, model bahasa N-gram, seperti unigram dan bigram, digunakan untuk menghitung probabilitas kemunculan kata dalam sebuah kalimat berdasarkan konteks kata-kata sebelumnya. Model bigram lebih unggul dibandingkan unigram karena mampu menangkap ketergantungan antara kata yang berdekatan, menghasilkan prediksi yang lebih akurat. Meskipun demikian, model n-gram mengalami masalah sparsity, yang dapat diatasi dengan menggunakan teknik seperti smoothing. Hasil analisis menunjukkan bahwa model bigram dengan smoothing memberikan hasil yang lebih baik daripada model unigram dalam banyak kasus, meskipun masih terdapat keterbatasan dalam menangkap ketergantungan kata yang lebih jauh dalam teks."]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[{"file_id":"https://github.com/aliakbars/uai-nlp/blob/main/tugas/tugas1.ipynb","timestamp":1745643222959}]}},"nbformat":4,"nbformat_minor":5}